{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the Dataset and the Aim of the EDA\n",
    "<img src=\"image.png\" alt=\"walmart black friday sale EDA banner\" style=\"width: 800px;\"/>\n",
    "\n",
    "The Management team at Walmart Inc. wants to analyze the customer purchase behavior (specifically, purchase amount) against the customer’s gender and the various other factors to help the business make better decisions. They want to understand if the spending habits differ between male and female customers\n",
    "\n",
    "Dataset\n",
    "\n",
    "The company collected the transactional data of customers who purchased products from the Walmart Stores during Black Friday. The dataset has the following features:\n",
    "Dataset link: Walmart_data.csv\n",
    "\n",
    "User_ID:\tUser ID\n",
    "Product_ID:\tProduct ID\n",
    "Gender:\tSex of User\n",
    "Age:\tAge in bins\n",
    "Occupation:\tOccupation(Masked)\n",
    "City_Category:\tCategory of the City (A,B,C)\n",
    "StayInCurrentCityYears:\tNumber of years stay in current city\n",
    "Marital_Status:\tMarital Status\n",
    "ProductCategory:\tProduct Category (Masked)\n",
    "Purchase:\tPurchase Amount\n",
    "\n",
    "What good looks like?\n",
    "\n",
    "Import the dataset and do usual data analysis steps like checking the structure & characteristics of the dataset.\n",
    "Detect Null values & Outliers (using boxplot, “describe” method by checking the difference between mean and median, isnull etc.)\n",
    "Do some data exploration steps like:\n",
    "Tracking the amount spent per transaction of all the 50 million female customers, and all the 50 million male customers, calculate the average, and conclude the results.\n",
    "Inference after computing the average female and male expenses.\n",
    "Use the sample average to find out an interval within which the population average will lie. Using the sample of female customers you will calculate the interval within which the average spending of 50 million male and female customers may lie.\n",
    "Use the Central limit theorem to compute the interval. Change the sample size to observe the distribution of the mean of the expenses by female and male customers.\n",
    "The interval that you calculated is called Confidence Interval. The width of the interval is mostly decided by the business: Typically 90%, 95%, or 99%. Play around with the width parameter and report the observations.\n",
    "Conclude the results and check if the confidence intervals of average male and female spends are overlapping or not overlapping. How can Walmart leverage this conclusion to make changes or improvements?\n",
    "Perform the same activity for Married vs Unmarried and Age\n",
    "For Age, you can try bins based on life stages: 0-17, 18-25, 26-35, 36-50, 51+ years.\n",
    "Give recommendations and action items to Walmart.\n",
    "Evaluation Criteria\n",
    "\n",
    "Defining Problem Statement and Analyzing basic metrics (10 Points)\n",
    "Observations on shape of data, data types of all the attributes, conversion of categorical attributes to 'category' (If required), statistical summary\n",
    "Non-Graphical Analysis: Value counts and unique attributes ​\n",
    "Visual Analysis - Univariate & Bivariate\n",
    "For continuous variable(s): Distplot, countplot, histogram for univariate analysis\n",
    "For categorical variable(s): Boxplot\n",
    "For correlation: Heatmaps, Pairplots\n",
    "Missing Value & Outlier Detection (10 Points)\n",
    "Business Insights based on Non- Graphical and Visual Analysis (10 Points)\n",
    "Comments on the range of attributes\n",
    "Comments on the distribution of the variables and relationship between them\n",
    "Comments for each univariate and bivariate plot\n",
    "Answering questions (50 Points)\n",
    "Are women spending more money per transaction than men? Why or Why not? (10 Points)\n",
    "Confidence intervals and distribution of the mean of the expenses by female and male customers (10 Points)\n",
    "Are confidence intervals of average male and female spending overlapping? How can Walmart leverage this conclusion to make changes or improvements? (10 Points)\n",
    "Results when the same activity is performed for Married vs Unmarried (10 Points)\n",
    "Results when the same activity is performed for Age (10 Points)\n",
    "Final Insights (10 Points) - Illustrate the insights based on exploration and CLT\n",
    "Comments on the distribution of the variables and relationship between them\n",
    "Comments for each univariate and bivariate plots\n",
    "Comments on different variables when generalizing it for Population\n",
    "Recommendations (10 Points)\n",
    "Actionable items for business. No technical jargon. No complications. Simple action items that everyone can understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scientific libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visual libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "import missingno as msno  # Visualize missing values\n",
    "\n",
    "# Helper libraries\n",
    "from tqdm.notebook import tqdm, trange # Progress bar\n",
    "#from colorama import Fore, Back, Style # coloured text in output\n",
    "import warnings \n",
    "#warnings.filterwarnings('ignore') # ignore all warkings\n",
    "\n",
    "# Visual setup\n",
    "%config InlineBackend.figure_format = 'retina' # sets the figure format to 'retina' for high-resolution displays.\n",
    "\n",
    "# Pandas options\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # display all interaction \n",
    "\n",
    "# Table styles\n",
    "from custom_styles import table_styles\n",
    "\n",
    "# Seed value for numpy.random\n",
    "np.random.seed(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category  Purchase  \n",
       "0                          2               0                 3      8370  \n",
       "1                          2               0                 1     15200  \n",
       "2                          2               0                12      1422  \n",
       "3                          2               0                12      1057  \n",
       "4                         4+               0                 8      7969  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_df = pd.read_csv('walmart_data.csv')\n",
    "wm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exploration and Data wrangling \n",
    "##  Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   User_ID                     550068 non-null  int64 \n",
      " 1   Product_ID                  550068 non-null  object\n",
      " 2   Gender                      550068 non-null  object\n",
      " 3   Age                         550068 non-null  object\n",
      " 4   Occupation                  550068 non-null  int64 \n",
      " 5   City_Category               550068 non-null  object\n",
      " 6   Stay_In_Current_City_Years  550068 non-null  object\n",
      " 7   Marital_Status              550068 non-null  int64 \n",
      " 8   Product_Category            550068 non-null  int64 \n",
      " 9   Purchase                    550068 non-null  int64 \n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 42.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.500680e+05</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.003029e+06</td>\n",
       "      <td>8.076707</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>5.404270</td>\n",
       "      <td>9263.968713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.727592e+03</td>\n",
       "      <td>6.522660</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>3.936211</td>\n",
       "      <td>5023.065394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.001516e+06</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5823.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.003077e+06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8047.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.004478e+06</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12054.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.006040e+06</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>23961.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User_ID     Occupation  Marital_Status  Product_Category  \\\n",
       "count  5.500680e+05  550068.000000   550068.000000     550068.000000   \n",
       "mean   1.003029e+06       8.076707        0.409653          5.404270   \n",
       "std    1.727592e+03       6.522660        0.491770          3.936211   \n",
       "min    1.000001e+06       0.000000        0.000000          1.000000   \n",
       "25%    1.001516e+06       2.000000        0.000000          1.000000   \n",
       "50%    1.003077e+06       7.000000        0.000000          5.000000   \n",
       "75%    1.004478e+06      14.000000        1.000000          8.000000   \n",
       "max    1.006040e+06      20.000000        1.000000         20.000000   \n",
       "\n",
       "            Purchase  \n",
       "count  550068.000000  \n",
       "mean     9263.968713  \n",
       "std      5023.065394  \n",
       "min        12.000000  \n",
       "25%      5823.000000  \n",
       "50%      8047.000000  \n",
       "75%     12054.000000  \n",
       "max     23961.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_df.info()\n",
    "wm_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Dataset\n",
    "Column                     | Description                          | Expected Data Type\n",
    "---------------------------|--------------------------------------|-------------------\n",
    "User_ID                    | Unique ID for user                   | int64\n",
    "Product_ID                 | Unique ID for product                | str / object\n",
    "Gender                     | Male / Female                        | Category\n",
    "Age                        | Age groups                           | Category\n",
    "Occupation                 | Unique code                          | Category\n",
    "City_Category              | A,B,C                                | Category\n",
    "Stay_In_Current_City_Years | Number of years stay in current city | Category\n",
    "Marital_Status             | 0/1                                  | Category\n",
    "Product_Category           | Unique code                          | Category\n",
    "Purchase                   | Amount                               | int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checklist List For the Dataset\n",
    "\n",
    "**Data Validation and Relationships**\n",
    "\n",
    "- Cross-Field Validation: Compare multiple variables to get cross-field validation like delivery date >= purchase date.\n",
    "    - Example: Check if the delivery date is always greater than or equal to the purchase date.\n",
    "- Data Leakage: Ensure that future information is not inadvertently included in the training data (especially relevant for time series or predictive modeling).\n",
    "    - Example: In a predictive model for stock prices, ensure that future stock prices are not included in the training data.\n",
    "- Referential Integrity: Validate foreign key relationships between tables or datasets.\n",
    "    - Example: Check if all order IDs in the orders table have a corresponding customer ID in the customers table.\n",
    "- Business Rules: Check for any specific business rules or domain-specific constraints that the data should adhere to.\n",
    "    - Example: In a retail dataset, check if the total order value is equal to the sum of item prices.\n",
    "- **Hierarchical Validation**: Validate the hierarchical relationships within the data, such as ensuring that a subcategory belongs to the correct main category.\n",
    "\t- Example: Check if all 'product_subcategory' values correctly correspond to their 'product_category' values.\n",
    "\n",
    "**Data Quality and Cleansing**\n",
    "\n",
    "- Handling Missing Data: Impute using mean or mode with or without grouping by other categories, and check for patterns in missingness.\n",
    "    - Example: Impute missing values in the 'age' column with the mean age grouped by 'gender'.\n",
    "    - Check category wise missing \n",
    "\t- MCAR, MAR, MNAR\n",
    "\t- For sting data type there could be entries like ' ' or 'unknown' like that which are essentially like a missing value (not an issue for category because we can catch it when we take value_counts())\n",
    "- Handling Outliers: \n",
    "\t- Remove outliers: In some cases, it may be appropriate to simply remove the observations that contain outliers. This can be particularly useful if you have a large number of observations and the outliers are not true representatives of the underlying population.\n",
    "\t- Transform outliers: The impact of outliers can be reduced or eliminated by transforming the feature. For example, a log transformation of a feature can reduce the skewness in the data, reducing the impact of outliers.\n",
    "\t- Impute outliers: In this case, outliers are simply considered as missing values. You can employ various imputation techniques for missing values, such as mean, median, mode, nearest neighbor, etc., to impute the values for outliers.\n",
    "\t- Use robust statistical methods: Some of the statistical methods are less sensitive to outliers and can provide more reliable results when outliers are present in the data. For example, we can use median and IQR for the statistical analysis as they are not affected by the outlier’s presence. This way we can minimize the impact of outliers in statistical analysis.\n",
    "\t- Use discretization or binning : converting numerical variables to categorical form can result in some loss of information, as the precise numerical values within each bin are no longer distinguished thus quality will be reduced thus accuracy of ML model but good for EDA\n",
    "\t  Use Freedman-Diaconis rule to get bin size (same is used by sns when you give bins=n) [numpy implementation](https://medium.com/@maxmarkovvision/optimal-number-of-bins-for-histograms-3d7c48086fde) \n",
    "    - Example: Identify and remove salary values that are more than 3 standard deviations away from the mean.\n",
    "- De-duplication: Handle duplicate records and quasi-duplicates (records that are almost identical but not exact duplicates).\n",
    "    - Example: Identify and remove duplicate customer records based on name, address, and phone number.\n",
    "\n",
    "**Data Transformation and Feature Engineering**\n",
    "\n",
    "- Categorical Constraint: Uncollapsed categories with the same or similar names, and check for categories with very low counts (which may need to be grouped or removed).\n",
    "    - Example: Group infrequent 'product_category' values into an 'Other' category.\n",
    "- Generating New Features: Create new features like the difference between purchase date and delivery date or segment numerical data into categorical bins.\n",
    "    - Example: Create a new feature 'delivery_time' as the difference between 'delivery_date' and 'purchase_date'.\n",
    "    - **Feature Engineering for Time Series**: For time series data, create features that capture temporal patterns, such as the day of the week, month, or season.\n",
    "    \t- Example: Add a 'day_of_week' column to a dataset with timestamps to capture weekly patterns.\n",
    "- Transform Data from Wide to Long: Reshape data from wide to long format, or vice versa, as needed for analysis.\n",
    "    - Example: Convert a dataset with multiple columns for different years (e.g., 'sales_2020', 'sales_2021') to a long format with 'year' and 'sales' columns.\n",
    "- Normalization and Scaling: Normalize or scale features as required for certain types of analyses or models.\n",
    "    - Example: Scale all features using StandardScaler before training a machine learning model.\n",
    "- Feature Selection: Identify and select the most relevant features for the analysis or modeling task.\n",
    "    - Example: Use a technique like correlation analysis or recursive feature elimination to select the most important features.\n",
    "\n",
    "**Data Representativeness**\n",
    "\n",
    "- Representative Data Check: Ensure that the data is representative of the population of interest, compare statistics of local and global populations, and mention any unrepresented populations for which conclusions may not apply.\n",
    "    - Example: Check if the income distribution in your dataset matches the population income distribution for the region of interest.\n",
    "- **Geographical Representativeness**: Ensure that the data is representative of the geographical area of interest, especially for location-based analyses.\n",
    "\t- Example: Verify that the dataset includes data from all relevant regions or cities for a comprehensive analysis.\n",
    "- Sample Size and Power: Check if the sample size is sufficient for the desired level of statistical power or precision.\n",
    "    - Example: Calculate the required sample size for a given effect size and desired statistical power before conducting an experiment.\n",
    "- Data Drift: Monitor for any significant changes or drifts in the data distribution over time (especially relevant for online or streaming data).\n",
    "    - Example: Track the mean and standard deviation of key features over time to detect any significant drifts in the data distribution.\n",
    "\n",
    "**General**\n",
    "\n",
    "- Documentation: Document all data cleaning and transformation steps, including the rationale behind each decision.\n",
    "    - Example: Maintain a data cleaning log that describes each step taken, why it was necessary, and any assumptions made.\n",
    "- Optimize DF to reduce space like changing data type to lower size\n",
    "- Version Control: Use version control to track changes to the data and the cleaning/transformation scripts.\n",
    "    - Example: Use Git to track changes to the data cleaning scripts and the cleaned datasets.\n",
    "- Reproducibility: Ensure that the data cleaning and transformation process is reproducible by others.\n",
    "    - Example: Create a Docker container or a virtual environment with all dependencies and scripts to ensure reproducibility.\n",
    "- - **Data Privacy and Security**: Ensure that the data cleaning process does not compromise data privacy or security, especially when handling sensitive information.\n",
    "\t- Example: Anonymize personally identifiable information (PII) before cleaning and analysis.\n",
    "- **Performance Monitoring**: Monitor the performance of the data cleaning process to identify bottlenecks and optimize the process.\n",
    "\t- Example: Use profiling tools to measure the time taken by each step of the data cleaning pipeline.\n",
    "- **Collaboration and Communication**: Ensure clear communication and collaboration among team members involved in the data cleaning process.\n",
    "\t- Example: Hold regular meetings to discuss data cleaning challenges and solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic sanity and preparation**\n",
    "* Renamed columns to snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>city_category</th>\n",
       "      <th>stay_in_current_city_years</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>product_category</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550063</th>\n",
       "      <td>1006033</td>\n",
       "      <td>P00372445</td>\n",
       "      <td>M</td>\n",
       "      <td>51-55</td>\n",
       "      <td>13</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550064</th>\n",
       "      <td>1006035</td>\n",
       "      <td>P00375436</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550065</th>\n",
       "      <td>1006036</td>\n",
       "      <td>P00375436</td>\n",
       "      <td>F</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550066</th>\n",
       "      <td>1006038</td>\n",
       "      <td>P00375436</td>\n",
       "      <td>F</td>\n",
       "      <td>55+</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550067</th>\n",
       "      <td>1006039</td>\n",
       "      <td>P00371644</td>\n",
       "      <td>F</td>\n",
       "      <td>46-50</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550068 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id product_id gender    age  occupation city_category  \\\n",
       "0       1000001  P00069042      F   0-17          10             A   \n",
       "1       1000001  P00248942      F   0-17          10             A   \n",
       "2       1000001  P00087842      F   0-17          10             A   \n",
       "3       1000001  P00085442      F   0-17          10             A   \n",
       "4       1000002  P00285442      M    55+          16             C   \n",
       "...         ...        ...    ...    ...         ...           ...   \n",
       "550063  1006033  P00372445      M  51-55          13             B   \n",
       "550064  1006035  P00375436      F  26-35           1             C   \n",
       "550065  1006036  P00375436      F  26-35          15             B   \n",
       "550066  1006038  P00375436      F    55+           1             C   \n",
       "550067  1006039  P00371644      F  46-50           0             B   \n",
       "\n",
       "       stay_in_current_city_years  marital_status  product_category  purchase  \n",
       "0                               2               0                 3      8370  \n",
       "1                               2               0                 1     15200  \n",
       "2                               2               0                12      1422  \n",
       "3                               2               0                12      1057  \n",
       "4                              4+               0                 8      7969  \n",
       "...                           ...             ...               ...       ...  \n",
       "550063                          1               1                20       368  \n",
       "550064                          3               0                20       371  \n",
       "550065                         4+               1                20       137  \n",
       "550066                          2               0                20       365  \n",
       "550067                         4+               1                20       490  \n",
       "\n",
       "[550068 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wm_df.rename(lambda x: x.lower(), axis='columns', inplace=True)\n",
    "wm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Integrity and Consistency**\n",
    "- Uniformity Constraint: Checked all data if in same unit or format like date, currency, scales\n",
    "- Data Type Constraint: Converted all category like variables to category data type with order specified\n",
    "- Data Range Constraints: No -ve values should be there in `purchases`\n",
    "- Uniqueness Constraint: `product id`, `user_id` should not be duplicated\n",
    "- Categorical Constraint: All categorical variables are ordered and no scope of collapsing because of similar name or very low in count for specific categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count   Dtype   \n",
      "---  ------                      --------------   -----   \n",
      " 0   user_id                     550068 non-null  int64   \n",
      " 1   product_id                  550068 non-null  object  \n",
      " 2   gender                      550068 non-null  category\n",
      " 3   age                         550068 non-null  category\n",
      " 4   occupation                  550068 non-null  category\n",
      " 5   city_category               550068 non-null  category\n",
      " 6   stay_in_current_city_years  550068 non-null  category\n",
      " 7   marital_status              550068 non-null  category\n",
      " 8   product_category            550068 non-null  category\n",
      " 9   purchase                    550068 non-null  int64   \n",
      "dtypes: category(7), int64(2), object(1)\n",
      "memory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data Type Constraint\n",
    "wm_df['gender'] = pd.Categorical(wm_df['gender'], ordered=True, categories=['M', 'F'])\n",
    "wm_df['age'] = pd.Categorical(wm_df['age'], ordered=True, categories=['0-17', '18-25', '26-35', '36-45', '46-50', '51-55', '55+'])\n",
    "wm_df['marital_status'] = pd.Categorical(wm_df['marital_status'], ordered=True, categories=[0, 1])\n",
    "wm_df['city_category'] = pd.Categorical(wm_df['city_category'], ordered=True, categories=['A', 'B', 'C'])\n",
    "wm_df['occupation'] = pd.Categorical(wm_df['occupation'], ordered=True, categories=[x for x in range(0, 21)])\n",
    "wm_df['stay_in_current_city_years'] = pd.Categorical(wm_df['stay_in_current_city_years'], ordered=True, categories=['0', '1', '2', '3', '4+'])\n",
    "wm_df['product_category'] = pd.Categorical(wm_df['product_category'], ordered=True, categories=[x for x in range(1, 21)])\n",
    "wm_df.info() # reduced size to 16.3 MB from 42 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "M    414259\n",
       "F    135809\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "age\n",
       "26-35    219587\n",
       "36-45    110013\n",
       "18-25     99660\n",
       "46-50     45701\n",
       "51-55     38501\n",
       "55+       21504\n",
       "0-17      15102\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "4     72308\n",
       "0     69638\n",
       "7     59133\n",
       "1     47426\n",
       "17    40043\n",
       "20    33562\n",
       "12    31179\n",
       "14    27309\n",
       "2     26588\n",
       "16    25371\n",
       "6     20355\n",
       "3     17650\n",
       "10    12930\n",
       "5     12177\n",
       "15    12165\n",
       "11    11586\n",
       "19     8461\n",
       "13     7728\n",
       "18     6622\n",
       "9      6291\n",
       "8      1546\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "city_category\n",
       "B    231173\n",
       "C    171175\n",
       "A    147720\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "stay_in_current_city_years\n",
       "1     193821\n",
       "2     101838\n",
       "3      95285\n",
       "4+     84726\n",
       "0      74398\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "marital_status\n",
       "0    324731\n",
       "1    225337\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "product_category\n",
       "5     150933\n",
       "1     140378\n",
       "8     113925\n",
       "11     24287\n",
       "2      23864\n",
       "6      20466\n",
       "3      20213\n",
       "4      11753\n",
       "16      9828\n",
       "15      6290\n",
       "13      5549\n",
       "10      5125\n",
       "12      3947\n",
       "7       3721\n",
       "18      3125\n",
       "20      2550\n",
       "19      1603\n",
       "14      1523\n",
       "17       578\n",
       "9        410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical Constraint: \n",
    "for col in wm_df.select_dtypes('category').columns:\n",
    "    wm_df[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Validation and Relationships**\n",
    "\n",
    "- Cross-Field Validation: Compare multiple variables to get cross-field validation like delivery date >= purchase date.\n",
    "    - Example: Check if the delivery date is always greater than or equal to the purchase date.\n",
    "- Data Leakage: Ensure that future information is not inadvertently included in the training data (especially relevant for time series or predictive modeling).\n",
    "    - Example: In a predictive model for stock prices, ensure that future stock prices are not included in the training data.\n",
    "- Referential Integrity: Validate foreign key relationships between tables or datasets.\n",
    "    - Example: Check if all order IDs in the orders table have a corresponding customer ID in the customers table.\n",
    "- Business Rules: Check for any specific business rules or domain-specific constraints that the data should adhere to.\n",
    "    - Example: In a retail dataset, check if the total order value is equal to the sum of item prices.\n",
    "- **Hierarchical Validation**: Validate the hierarchical relationships within the data, such as ensuring that a subcategory belongs to the correct main category.\n",
    "\t- Example: Check if all 'product_subcategory' values correctly correspond to their 'product_category' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assertions and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformity Constraint assertions\n",
    "assert wm_df['product_id'].str.startswith('P').all() == True\n",
    "\n",
    "# Data type assertions\n",
    "assert wm_df['user_id'].dtype == 'int64'\n",
    "assert wm_df['product_id'].dtype == 'object'\n",
    "assert wm_df['gender'].dtype == 'category'\n",
    "assert wm_df['age'].dtype == 'category'\n",
    "assert wm_df['occupation'].dtype == 'category'\n",
    "assert wm_df['city_category'].dtype == 'category'\n",
    "assert wm_df['stay_in_current_city_years'].dtype == 'category'\n",
    "assert wm_df['marital_status'].dtype == 'category'\n",
    "assert wm_df['product_category'].dtype == 'category'\n",
    "assert wm_df['purchase'].dtype == 'int64'\n",
    "\n",
    "# Data Range Constraints\n",
    "# No -ve values in purchases\n",
    "assert wm_df['purchase'].ge(0).all() == True\n",
    "\n",
    "# Uniqueness Constraint\n",
    "wm_df[['user_id','product_id']].duplicated().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
